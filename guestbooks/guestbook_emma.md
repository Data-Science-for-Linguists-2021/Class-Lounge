#### Welcome to Emma's Project Guestbook:
## [Analyzing Political Rhetoric](https://github.com/Data-Science-for-Linguists-2021/PoliticalRhetoric-analysis)

### Vist (Emily)
> Thank you for looking over my project! The long section of text/big data frames point was very helpful and was definitely true haha!

- I like the organization of your jupyter notebook, it is easy to follow and your notes explaining the steps help as well.
- There were some sections where you printed very long sections of text/big dataframes. I think in general limiting it would make the notebook easier to  follow, but I know it is a work in progress:)
- I learned a nice easy function for dropping duplicates in a dataframe (.drop_duplicates()), looks very handy.


### Visit (Abby)
> Thank you for stopping by my guestbook, Abby! The possible features that you gave are really interesting - I needed help coming up with more ways to go about my analysis, so this was perfect! Also, I’m super glad you pointed out the two politicians and their affiliations, I’ll have to check over that when I go further with my analysis!

- I really like your topic choice and overall organization.  You very wisely chose a somewhat preprocessed dataset, which looked like it saved a lot of time.
- This may be personal preference, but I think it would be interesting to consider more features.  For instance, does being from the west coast
	versus the east coast make more of a difference than political party affiliation in terms of linguistic style?  What about speeches from
	2008 versus speeches from 2020?  Also, there are two errors from one of the kaggle data sets!  Both John Kasich and Colin Powell are
	listed as democrats, but they're actually center-right republicans.
- A really easy way to get rid of unwanted string values is by doing word.strip(unwanted string) in list comprehension.  I overcomplicated
	this in my own data by using regex to substitue an empty value for the unwanted string. strip() is much easier.

### Visit (Sonia)
> Thank you for visiting my guestbook and project, Sonia! Your suggestion on working with the analysis was super helpful, I didn’t know about that concept, but it makes a lot of sense!

- This topic is really interesting; exctracting very different most common words or building classifiers that achieve high accuracy would really highlight how different the two parties are. Also I like how you're looking at rhetoric from different samples for different audiences, that's really going to help the analysis be pretty comprehensive.
- Just a suggestion going forwards, I would think to try completing all the technical aspect of the analysis for just one of the mediums/datasets to begin with. If there's an issue at the very last step of analysis, you then have a month to fix it rather than a week. Then, doing the analysis with the other datasets is similar and should be easier or less overwhelming. This comes from a software engineering concept called "minimum viable product", where you try to get something rough but complete to show for your efforts and then you can go back and add in lots later.
- I've got pretty informal knowledge of politics, so I never knew the parties have literal "Party Platforms" out there spelling out their stance.

### Visit (Michael)
> Thank you, Michael, for your comments! I’m glad you find the concept of my project intriguing, and I’m grateful for your suggestion to include an additional notebook for major findings!

- It seems like you have plenty of data for your analysis, and I like how you organize the analyses into different notebooks. Overall, this seems like a very intriguing concept with some potential real-world applicability!
- I might recommend, for the presentation portion, adding an additional notebook to summarize the major findings from each analysis and (potentially) draw some larger conclusions.
- I learned that nltk has a customizable regex tokenizer, which seems like it could be very helpful for my own project.

### Visit (Frances)
> Thank you for visiting my project, Frances! I found the top words pretty interesting, as well, so it was nice to see you shared in that! The neutral category was something that I added purely out of curiosity to see what the top features would be without doing any super complex computing to be honest!

- It’s really great how you used a few different ML models and toggled the features.
- This isn’t exactly a problem, but I’m curious about what the purpose of the random “neutral” category is (the “yo”).
- The top words (especially from the debate section) were really interesting to see, and weird that “republican” was one of the top words used by the Democratic side!
